{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting the Dogon comparative wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steven Moran &lt;bambooforest@gmail.com&gt;\n",
    "\n",
    "The latest version of this [Jupyter notebook](http://jupyter.org/) is available at [https://github.com/unicode-cookbook](https://ithub.com/unicode-cookbook). \n",
    "\n",
    "This use case illustrates how to segment wordlist data using an orthography profile. Details about orthography profiles and more is available in the [Unicode Cookbook](https://github.com/unicode-cookbook).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Dogon and Bangime linguistics](http://dogonlanguages.org/) project collects and disseminates linguistic, cultural and geographic data from fieldwork undertaken on the Dogon languages (and Bangime) spoken in Mali. \n",
    "\n",
    "The data includes an extensive comparative [Dogon lexicon](https://github.com/clld/dogonlanguages-data) organized in an Excel spreadsheet. Columns include more than 20 linguistic varieties of Dogon, Englisd and French glosses, and semantic domains. The spreadsheet contains over 8000 rows, where each row is a semantic concept.\n",
    "\n",
    "The comparative wordlist was compiled by fieldworkers and each fieldworker has their own system for transcription. This will be made clear below when we create an initial orthography profile from the wordlist; it highlights idiosyncracies between transcription practives, e.g. there is both &lt;aa&gt; and &lt;aː&gt;.\n",
    "\n",
    "For this recipe, we will use a smaller curated version of the comparative Dogon wordlist available in the `sources` directory of this recipe. The wordlist is in CSV format with columns for a row ID, concept, doculect (language variety) and counterpart (word in the language).\n",
    "\n",
    "We will use the Python library [Pandas](http://pandas.pydata.org/) for the CSV reading and manipulation of the word list. The orthography profile for the Dogon lexical data is located in the `data` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started import the [segments](https://pypi.python.org/pypi/segments/) and [Pandas](http://pandas.pydata.org/) modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from segments.tokenizer import Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word list, for Pandas specify a row index column, and have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 CONCEPT         DOCULECT COUNTERPART\n",
      "ID                                                   \n",
      "1   -teen ('11' to '19')          Ben_Tey        sâ:\n",
      "2   -teen ('11' to '19')        Dogul_Dom      sìgà\n",
      "3   -teen ('11' to '19')           Gourou      sáɣà\n",
      "4   -teen ('11' to '19')  Jamsay_Douentza      sáɣà\n",
      "5   -teen ('11' to '19')          Najamba      sìgà\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sources/dogon-wordlist.tsv\", index_col=\"ID\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dogon orthography profile is in the `data` directory. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! more data/Heath2016-profile.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tokenizer object from the orthography profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(\"data/Heath2016-profile.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add to our word list an additional column called `IPA` that will contain the output from orthography profile segmentation of the `COUNTERPART` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = lambda x: t.transform(x, column=\"IPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 CONCEPT         DOCULECT COUNTERPART     TOKENS\n",
      "ID                                                              \n",
      "1   -teen ('11' to '19')          Ben_Tey        sâ:      s âː\n",
      "2   -teen ('11' to '19')        Dogul_Dom      sìgà  s ì ɡ à\n",
      "3   -teen ('11' to '19')           Gourou      sáɣà  s á ɣ à\n",
      "4   -teen ('11' to '19')  Jamsay_Douentza      sáɣà  s á ɣ à\n",
      "5   -teen ('11' to '19')          Najamba      sìgà  s ì ɡ à\n"
     ]
    }
   ],
   "source": [
    "df['TOKENS'] = pd.Series(df['COUNTERPART'].apply(tokenizer))())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 CONCEPT         DOCULECT COUNTERPART     TOKENS\n",
      "ID                                                              \n",
      "1   -teen ('11' to '19')          Ben_Tey        sâ:      s âː\n",
      "2   -teen ('11' to '19')        Dogul_Dom      sìgà  s ì ɡ à\n",
      "3   -teen ('11' to '19')           Gourou      sáɣà  s á ɣ à\n",
      "4   -teen ('11' to '19')  Jamsay_Douentza      sáɣà  s á ɣ à\n",
      "5   -teen ('11' to '19')          Najamba      sìgà  s ì ɡ à\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the new segmented wordlist to the `sandbox` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('sandbox/segmented-dogon-wordlist.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an initial orthography profile from text input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already provided you with a well-tested and curated orthography profile for the Dogon data. But if you want to create an initial profile, this is how you could do it from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
