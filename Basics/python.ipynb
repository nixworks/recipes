{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of grapheme segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steven Moran &lt;bambooforest@gmail.com&gt;\n",
    "\n",
    "The latest version of this [Jupyter notebook](http://jupyter.org/) is available at [https://github.com/unicode-cookbook/recipes/Basics](https://github.com/unicode-cookbook/recipes/Basics). \n",
    "\n",
    "This use case illustrates how to segment text into graphemes. We also transliterate graphemes using an orthography profile. Details about orthography profiles and more is available in the [Unicode Cookbook for Linguists](https://github.com/unicode-cookbook/cookbook).\n",
    "\n",
    "This recipes uses Python 3.5. \n",
    "\n",
    "Github renders Jupyter notebooks nicely, so you can copy and paste code into your interpreter or scripts. If you however `git clone` the `recipes` repository and have Jupyter installed on your machine, this file is also executable in your own browser. Run `jupyter notebook` in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Python [segments](https://pypi.python.org/pypi/segments/) package to tokenize characters, graphemes and IPA. Installation instructures here: [https://github.com/unicode-cookbook/recipes](https://github.com/unicode-cookbook/recipes). We illustrate both API access and the command line program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segments.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `characters` function will segment a string at Unicode code points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c ̂ h a ́ ɾ a ̃ ̌ c t ʼ ɛ ↗ ʐ ː | # k ͡ p\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "result = t.characters(\"ĉháɾã̌ctʼɛ↗ʐː| k͡p\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `grapheme_clusters` function will segment text at the [Unicode Extended Grapheme Cluster](http://www.unicode.org/reports/tr18/tr18-19.html#Default_Grapheme_Clusters) boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĉ h á ɾ ã̌ c t ʼ ɛ ↗ ʐ ː | # k͡ p\n"
     ]
    }
   ],
   "source": [
    "result = t.grapheme_clusters(\"ĉháɾã̌ctʼɛ↗ʐː| k͡p\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `grapheme_clusters` function is also the default segmentation algorithm for the `segments.Tokenizer`. It is useful when you encounter a text that you want to tokenize to identify orthographic or transcription elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĉ h á ɾ ã̌ c t ʼ ɛ ↗ ʐ ː | # k͡ p\n"
     ]
    }
   ],
   "source": [
    "result = t(\"ĉháɾã̌ctʼɛ↗ʐː| k͡p\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ipa` parameter forces grapheme segmentation for [IPA strings](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) (a formal definition is given in [Chapter 5](https://github.com/unicode-cookbook/cookbook))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĉ h á ɾ ã̌ c tʼ ɛ ↗ ʐː | # k͡p\n"
     ]
    }
   ],
   "source": [
    "result = t(\"ĉháɾã̌ctʼɛ↗ʐː| k͡p\", ipa=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load an orthography profile and tokenize input string with it. In the `data` directory we've placed an example orthograpy profile. Let's have a look at it using `more` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "Grapheme        IPA     XSAMPA  COMMENT\r\n",
      "a       a       a\r\n",
      "aa      aː      a:\r\n",
      "b       b       b\r\n",
      "c       c       c\r\n",
      "ch      tʃ      tS\r\n",
      "-       NULL    NULL    \"comment with   tab\"\r\n",
      "on      õ       o~\r\n",
      "n       n       n\r\n",
      "ih      í       i_H\r\n",
      "inh     ĩ́       i~_H\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more data/orthography-profile.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An orthograpy profile is tab-delimited UTF-8 text file. The first column must be labelled `Grapheme`. Each row in the `Grapheme` column specifies graphemes that may be found in the orthography of the input text. In this example, we provide additional columns `IPA` and `XSAMPA`, which are mappings from our graphemes to their [IPA](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) and [XSAMPA](https://en.wikipedia.org/wiki/X-SAMPA) transliterations. The final column `COMMENT` is for comments; if you want to use a tab ''quote that&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;string''!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the orthography profile with our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segments.tokenizer import Profile\n",
    "\n",
    "t = Tokenizer('data/orthography-profile.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's segment the graphemes in some input strings with our orthography profile. The output is segmented given the definition of graphemes in our orthography profile, e.g. we specified the sequence of two &lt;a a&gt; should be a single unit &lt;aa&gt;, and so should the sequences &lt;c h&gt;, &lt;o n&gt; and &lt;i h&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa b ch on n - ih'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t('aabchonn-ih')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how can we tokenize input text into our orthograpic specification. We can also segment graphemes and transliterate them into other formats, which is useful when you have sources with different orthographies, but you want to be able to compare them using a single representation like IPA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aː b tʃ õ n í'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.transform(\"aabchonn-ih\", \"IPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a: b tS o~ n i_H'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.transform(\"aabchonn-ih\", \"XSAMPA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to know which characters in your input string are not in your orthography profile. Use the function `find_missing_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa b ch on n - ih � � �'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.find_missing_characters(\"aa b ch on n - ih x y z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the default as the [Unicode replacement character \\ufffd](http://www.fileformat.info/info/unicode/char/fffd/index.htm). But you can simply change this by specifying the replacement character when you load the orthography profile with the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa b ch on n - ih ? ? ?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Tokenizer('data/orthography-profile.tsv', errors_replace=lambda c: '?')\n",
    "t.find_missing_characters(\"aa b ch on n - ih x y z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa b ch on n - ih <x> <y> <z>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Tokenizer('data/orthography-profile.tsv', errors_replace=lambda c: '<{0}>'.format(c))\n",
    "t.find_missing_characters(\"aa b ch on n - ih x y z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you want to create an initial orthography profile that also contains those graphemes x, y, z?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grapheme\tfrequency\tmapping\n",
      " \t9\t \n",
      "a\t2\ta\n",
      "h\t2\th\n",
      "n\t2\tn\n",
      "b\t1\tb\n",
      "c\t1\tc\n",
      "o\t1\to\n",
      "-\t1\t-\n",
      "i\t1\ti\n",
      "x\t1\tx\n",
      "y\t1\ty\n",
      "z\t1\tz\n"
     ]
    }
   ],
   "source": [
    "profile = Profile.from_text(\"aa b ch on n - ih x y z\")\n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Command line access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to `pip install segments` to install the command line tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some help with `segments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: segments [-h] [--verbosity VERBOSITY] [--encoding ENCODING]\r\n",
      "                [--profile PROFILE] [--mapping MAPPING]\r\n",
      "                command ...\r\n",
      "\r\n",
      "Main command line interface of the segments package.\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  command               tokenize | profile\r\n",
      "  args\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --verbosity VERBOSITY\r\n",
      "                        increase output verbosity\r\n",
      "  --encoding ENCODING   input encoding\r\n",
      "  --profile PROFILE     path to an orthography profile\r\n",
      "  --mapping MAPPING     column name in ortho profile to map graphemes\r\n",
      "\r\n",
      "Use 'segments help <cmd>' to get help about individual commands.\r\n"
     ]
    }
   ],
   "source": [
    "!segments -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "aäaaöaaüaa\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sources/text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grapheme\tfrequency\tmapping\r\n",
      "a\t7\ta\r\n",
      "ä\t1\tä\r\n",
      "ö\t1\tö\r\n",
      "ü\t1\tü\r\n"
     ]
    }
   ],
   "source": [
    "!cat sources/text.txt | segments profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat sources/text.txt | segments profile > sandbox/orthography-profile.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "Grapheme        frequency       mapping\r\n",
      "a       7       a\r\n",
      "ä       1       ä\r\n",
      "ö       1       ö\r\n",
      "ü       1       ü\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sandbox/orthography-profile.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ä a a ö a a ü a a\r\n"
     ]
    }
   ],
   "source": [
    "!cat sources/text.txt | segments tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ä a a ö a a ü a a\r\n"
     ]
    }
   ],
   "source": [
    "!cat sources/text.txt | segments --mapping=mapping --profile=sandbox/orthography-profile.tsv tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
